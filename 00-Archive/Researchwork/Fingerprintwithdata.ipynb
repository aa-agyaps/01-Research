{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import traceback\n",
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, DotProduct, Matern, RationalQuadratic, Exponentiation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from tensorflow.keras import layers\n",
    "from rdkit import Chem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import AllChem"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data as a pandas dataframe\n",
    "#df = pd.read_csv (r'C:\\Users\\Ama\\OneDrive - Southern University System\\02-MachineLearning\\Dataset_for_practise\\SMP-Eg - Copy.csv')\n",
    "df = pd.read_csv(r\"C:\\Users\\Ama\\OneDrive - Southern University System\\02-MachineLearning\\Dataset_for_practise\\SMP-Eg.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting data into appropriate shape\n",
    "smiles = df['SMILES']\n",
    "smiles = [list(smile.strip('{} ').split(',')) for smile in smiles]\n",
    "\n",
    "molar_ratio = df['Molar Ratio']\n",
    "m_r = []\n",
    "for entry in molar_ratio:\n",
    "    ratio_list = [float(x) for x in entry.split(':')]\n",
    "    m_r.append(ratio_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''''\n",
    "functions for fingerprinting and multiplication of \n",
    "fingerprinted monomers by their respective molar ratios\n",
    "'''\n",
    "#function for fingerprinting\n",
    "def fingerprint_monomer(monomer):\n",
    "    mol = Chem.MolFromSmiles(monomer)\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 8, 2028)\n",
    "    return fp\n",
    "\n",
    "#function for storing fingerprints monomers as a representation of the polymers\n",
    "def fingerprint_polymer(polymer):\n",
    "    polymer_fp = []\n",
    "    for monomer in polymer:\n",
    "        monomer_fp = fingerprint_monomer(monomer)\n",
    "        polymer_fp.append(monomer_fp)\n",
    "    return polymer_fp\n",
    "\n",
    "# function for multiplication by their respective molar ratios\n",
    "def multiply_fingerprint(fp, m_r_value):\n",
    "    return np.multiply(fp, m_r_value)\n",
    "\n",
    "fingerprinted_polymer_data = []\n",
    "for polymer, polymer_m_r in zip(smiles, m_r):\n",
    "    fingerprinted_polymer = fingerprint_polymer(polymer)\n",
    "    multiplied_polymer = [multiply_fingerprint(fp, m_r_value) for fp, m_r_value in zip(fingerprinted_polymer, polymer_m_r)]\n",
    "    fingerprinted_polymer_data.append(multiplied_polymer)\n",
    "    \n",
    "\n",
    "#flatten the array created and storing them in a list\n",
    "flattened_arr = [np.concatenate(arr) for arr in fingerprinted_polymer_data]\n",
    "\n",
    "#find the maximum length of the flattened arrays\n",
    "max_length = max(len(arr) for arr in flattened_arr)\n",
    "\n",
    "# pad the arrays with zeros to make them the same length\n",
    "padded_arrays = [np.pad(arr, (0, max_length - len(arr)), mode = 'constant') for arr in flattened_arr]\n",
    "\n",
    "new_array = np.stack(padded_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_array\n",
    "y = df['Glassy Modulus'] #specify y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**THE MODELS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into training and testing sets\n",
    "random_seed = 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.1, random_state= random_seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_rbf = SVR(kernel=\"rbf\", C=100, gamma='scale', epsilon=0.2)\n",
    "svr_lin = SVR(kernel=\"linear\", C=100, gamma=\"scale\", epsilon=0.2)\n",
    "svr_poly = SVR(kernel=\"poly\", C=100, gamma=\"scale\", degree=3, epsilon=0.2, coef0=1)\n",
    "\n",
    "lw = 3\n",
    "\n",
    "svrs = [svr_rbf, svr_lin, svr_poly]\n",
    "kernel_label = [\"RBF\", \"Linear\", \"Polynomial\"]\n",
    "model_color = [\"m\", \"c\", \"g\"]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 4), sharey=True)\n",
    "for ix, svr in enumerate(svrs):\n",
    "    predicted_values = svr.fit(X_train, y_train).predict(X_test)\n",
    "    axes[ix].scatter(\n",
    "        predicted_values,\n",
    "        y_test,\n",
    "        color=model_color[ix],\n",
    "        lw=lw,\n",
    "        label=\"{} kernel\".format(kernel_label[ix]),\n",
    "    )\n",
    "    axes[ix].plot(\n",
    "        x_plot,\n",
    "        y_plot, color = 'black'\n",
    "    )\n",
    "    axes[ix].legend(\n",
    "        loc=\"upper center\",\n",
    "        bbox_to_anchor=(0.6, 1),\n",
    "        ncol=1,\n",
    "        fancybox=True,\n",
    "        shadow=True,\n",
    "    )\n",
    "    # Calculate the MAPE\n",
    "    mape = mean_absolute_percentage_error(y_test, predicted_values)\n",
    "    mse = mean_squared_error(y_test, predicted_values)\n",
    "    mae = mean_absolute_error(y_test, predicted_values)\n",
    "\n",
    "    # Display the MAE as text annotation on the plot\n",
    "    axes[ix].text(\n",
    "        0.05,\n",
    "        0.95,\n",
    "        f\"MAPE: {mape:.2f}\\nMSE: {mse:.2f}\\nMAE: {mae:.2f}\",\n",
    "        transform=axes[ix].transAxes,\n",
    "        ha=\"left\",\n",
    "        va=\"top\",\n",
    "        fontsize=10,\n",
    "        bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.4'),\n",
    "    )\n",
    "    axes[ix].text(\n",
    "    11.9,\n",
    "    12,\n",
    "    \"X = y\",\n",
    "    rotation=44,\n",
    "    fontsize = 15,\n",
    "    verticalalignment='bottom',\n",
    "    )\n",
    " \n",
    "fig.text(0.5, 0.0, \"predicted\", ha=\"center\", va=\"center\")\n",
    "fig.text(0.06, 0.5, \"actual\", ha=\"center\", va=\"center\", rotation=\"vertical\")\n",
    "fig.suptitle(\"Support Vector Regression\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "# Define the ANN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mae',optimizer=optimizer, metrics=['mape','mse, mae'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=1000,  batch_size= 32, validation_data=(X_test, y_test))\n",
    "# Predict on the test set\n",
    "predicted_values = model.predict(X_test)\n",
    "\n",
    "# Calculate the error\n",
    "mape = mean_absolute_percentage_error(y_test, predicted_values)\n",
    "mse = mean_squared_error(y_test, predicted_values)\n",
    "mae = mean_absolute_error(y_test, predicted_values)\n",
    "\n",
    "# Plotting\n",
    "lw = 1\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "ax.scatter(\n",
    "    predicted_values,\n",
    "    y_test,\n",
    "    color='b',\n",
    "    lw=lw,\n",
    "    label=\"Predicted vs Actual\"\n",
    ")\n",
    "ax.plot(\n",
    "    x_plot,\n",
    "    y_plot,\n",
    "    color='black'\n",
    ")\n",
    "\n",
    "# Display the MAE as text annotation on the plot\n",
    "ax.text(\n",
    "    0.6,\n",
    "    1,\n",
    "    f\"MAPE: {mape:.2f}\\nMSE: {mse:.2f}\\nMAE: {mae:.2f}\",\n",
    "    transform=ax.transAxes,\n",
    "    ha=\"left\",\n",
    "    va=\"top\",\n",
    "    fontsize=10,\n",
    "    bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.4'),\n",
    ")\n",
    "ax.text(\n",
    "    11.9,\n",
    "    12,\n",
    "    \"X = y\",\n",
    "    rotation=44,\n",
    "    fontsize = 15,\n",
    "    verticalalignment='bottom',\n",
    "    )\n",
    "\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('Actual')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#mape, mae = model.evaluate(X_test, y_test)\n",
    "#print('Test Mean Absolute Error:', mape)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of kernels to evaluate\n",
    "kernels = [\n",
    "    1.0 * RBF(length_scale=1.0),\n",
    "    1.0 * Matern(length_scale=1.0, nu=2.0),\n",
    "    1.0 * RationalQuadratic(length_scale=2.0),\n",
    "    1.0 * DotProduct(sigma_0=2.0, sigma_0_bounds=(1e-6, np.inf)),\n",
    "    1.0 * Exponentiation(kernel= RBF(), exponent=2)\n",
    "]\n",
    "\n",
    "# Initialize lists to store AIC and models\n",
    "aic_scores = []\n",
    "models = []\n",
    "\n",
    "# Perform GPR with different kernels and calculate AIC scores\n",
    "for kernel in kernels:\n",
    "    gpr = GaussianProcessRegressor(kernel=kernel, alpha=1.0, random_state = 10)\n",
    "    gpr.fit(X_train, y_train)\n",
    "    y_pred = gpr.predict(X_test)\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    n_params = len(gpr.kernel.theta)\n",
    "    aic = 2 * n_params + len(X_train) * np.log(mape)\n",
    "    aic_scores.append(aic)\n",
    "    models.append(gpr)\n",
    "\n",
    "# Find the model with the minimum AIC score\n",
    "best_model_idx = np.argmin(aic_scores)\n",
    "best_model = models[best_model_idx]\n",
    "\n",
    "# Fit the best model to the entire dataset\n",
    "best_model.fit(X_train, y_train)\n",
    "print(best_model)\n",
    "\n",
    "# Perform prediction with the best model\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "\n",
    "# Calculate the error\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Plotting\n",
    "lw = 1\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "ax.scatter(\n",
    "    y_pred,\n",
    "    y_test,\n",
    "    color='r',\n",
    "    lw=lw,\n",
    "    label=\"Predicted vs Actual\"\n",
    ")\n",
    "ax.plot(\n",
    "    x_plot,\n",
    "    y_plot,\n",
    "    color='black'\n",
    ")\n",
    "\n",
    "# Display the MAE as text annotation on the plot\n",
    "ax.text(\n",
    "    0.6,\n",
    "    1,\n",
    "    f\"MAPE: {mape:.2f}\\nMSE: {mse:.2f}\\nMAE: {mae:.2f}\",\n",
    "    transform=ax.transAxes,\n",
    "    ha=\"left\",\n",
    "    va=\"top\",\n",
    "    fontsize=10,\n",
    "    bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.4'),\n",
    ")\n",
    "ax.text(\n",
    "    11.9,\n",
    "    12,\n",
    "    \"X = y\",\n",
    "    rotation=44,\n",
    "    fontsize = 10,\n",
    "    verticalalignment='bottom',\n",
    "    )\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('Actual')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
